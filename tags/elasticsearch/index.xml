<?xml version="1.0" encoding="utf-8" standalone="yes" ?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Elasticsearch on Kanekotic</title>
    <link>http://kanekotic.github.io/tags/elasticsearch/</link>
    <description>Recent content in Elasticsearch on Kanekotic</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>en-us</language>
    <copyright>&amp;copy; 2018</copyright>
    <lastBuildDate>Wed, 27 Apr 2016 00:00:00 +0000</lastBuildDate>
    
	<atom:link href="http://kanekotic.github.io/tags/elasticsearch/index.xml" rel="self" type="application/rss+xml" />
    
    
    <item>
      <title>ELK Docker</title>
      <link>http://kanekotic.github.io/project/elk-docker/</link>
      <pubDate>Wed, 27 Apr 2016 00:00:00 +0000</pubDate>
      
      <guid>http://kanekotic.github.io/project/elk-docker/</guid>
      <description>This show how multiple containers can aggregate log to logging infrastructure with docker compose using logstash, elastic search and kibana
Run you will need docker installed in your computer, after it :
 Run  docker-compose up   run to get some logs from httpd  repeat 10 curl http://localhost:80/   Kibana:
 this might take a bit Navigate to http://localhost:5601 Add logstash-* as index with @timestamp as Time-field name Go to Discover  Grafana:</description>
    </item>
    
  </channel>
</rss>